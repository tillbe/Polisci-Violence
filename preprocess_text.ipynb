{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import pymongo\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "from os.path import basename"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ReadMe\n",
    "\n",
    "This script reads in the newspaper articles in text files form and stores it in a MongoDB database. Articles are processed such that bylines etc. are removed. Articles are then merged with data from the codebook, identifying which debate etc. the article is about."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "client = pymongo.Connection()\n",
    "collection = client.politics.debates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cleanText(filename):\n",
    "    \"\"\"\n",
    "    Cleans the article from unnecessary information, such as bylines and copyright information.\n",
    "    @param filename: filename of the article to read.\n",
    "    returns a string containing the article text stripped of unnecessary information.\n",
    "    \"\"\"\n",
    "    with open(filename) as fh:\n",
    "        txt = []\n",
    "        for line in fh:\n",
    "            upper = re.match(\"[A-Za-z-]+:\", line) # checks if line contains meta information we don't need\n",
    "            white = re.match(\"\\s+\", line) # checks if line contains copyright etc informations (starting with whitespace)\n",
    "            if not upper and not white: txt.append(re.sub(\"\\d\",\"\", line)) # appends and removes digits\n",
    "    return(\"\".join(txt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convertTypes(value):\n",
    "    \"\"\"\n",
    "    Converts numpy integers to normal integers, in order to store values in MongoDB database.\n",
    "    \"\"\"\n",
    "    if isinstance(value, np.int64):\n",
    "        return(int(value))\n",
    "    else:\n",
    "        return(value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have additional information about each article in a separate codebook. \n",
    "This reads the code book in and changes the columns names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"data/2012/DebateCodeBook5.2015.xlsx\")\n",
    "df.columns = [\"_id\", \"title\", \"debate\", \"days_after\", \"year\", \"newspaper\", \"word_count\"]\n",
    "df.index = df[\"_id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>title</th>\n",
       "      <th>debate</th>\n",
       "      <th>days_after</th>\n",
       "      <th>year</th>\n",
       "      <th>newspaper</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>EIGHT Questions</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2012</td>\n",
       "      <td>Washington Post</td>\n",
       "      <td>2215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>The Denver Presidential Debate: Panel Verdict</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2012</td>\n",
       "      <td>The Guardian</td>\n",
       "      <td>2548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Battling on the Home Front</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2012</td>\n",
       "      <td>The Globe and Mail</td>\n",
       "      <td>2044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>After Debate, a Torrent of Criticism for Obama</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2012</td>\n",
       "      <td>The New York Times</td>\n",
       "      <td>1476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>REBOUNDING ROMNEY Mitt recharged after debate win</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2012</td>\n",
       "      <td>Daily News</td>\n",
       "      <td>1448</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     _id                                              title  debate  \\\n",
       "_id                                                                   \n",
       "1      1                                    EIGHT Questions       1   \n",
       "2      2      The Denver Presidential Debate: Panel Verdict       1   \n",
       "3      3                         Battling on the Home Front       1   \n",
       "4      4     After Debate, a Torrent of Criticism for Obama       1   \n",
       "5      5  REBOUNDING ROMNEY Mitt recharged after debate win       1   \n",
       "\n",
       "     days_after  year           newspaper  word_count  \n",
       "_id                                                    \n",
       "1             0  2012     Washington Post        2215  \n",
       "2             1  2012        The Guardian        2548  \n",
       "3             0  2012  The Globe and Mail        2044  \n",
       "4             2  2012  The New York Times        1476  \n",
       "5             2  2012          Daily News        1448  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reads in all the text files to be stored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data/2012/1.TXT',\n",
       " 'data/2012/10.TXT',\n",
       " 'data/2012/100.TXT',\n",
       " 'data/2012/101.TXT',\n",
       " 'data/2012/102.TXT']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = glob(\"data/2012/*.TXT\")\n",
    "files[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loops through the files, processes them and inserts them into the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "for f in tqdm(files):\n",
    "    i = int(basename(f).split(\".\")[0]) # gets the ID of the article, aka the filename without extension\n",
    "    d = df.loc[i].to_dict() # gets the matching row from the codebook\n",
    "    d['text'] = cleanText(f) # adds the cleaned text to the dict\n",
    "    d = {key:convertTypes(value) for key,value in d.items()} # converts numpy ints to normal ints\n",
    "    collection.insert(d) # inserts into database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stem words\n",
    "\n",
    "In this section, all articles are tokenized and stemmed. The stemmed words are stored in the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import string\n",
    "import re\n",
    "\n",
    "from nltk.stem import SnowballStemmer \n",
    "from nltk.tokenize import word_tokenize \n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sb = SnowballStemmer(\"english\")\n",
    "stops = stopwords.words(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def stemWords(text, t = True):\n",
    "    if t:\n",
    "        tokens = word_tokenize(text)\n",
    "    else:\n",
    "        tokens = text\n",
    "    out = []\n",
    "    for token in tokens:\n",
    "        #token = re.sub(\"\\d\",\"\", token)\n",
    "        token = remove_punctuation(token.lower())\n",
    "        if len(token) > 2 and token not in stops: out.append(sb.stem(token))\n",
    "    return(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def remove_punctuation(s):\n",
    "    \"\"\"see http://stackoverflow.com/questions/265960/best-way-to-\\\n",
    "    strip-punctuation-from-a-string-in-python\"\"\"\n",
    "#     table = str.maketrans(\"\", \"\")\n",
    "    return s.translate(str.maketrans(\"\",\"\", string.punctuation)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "cursor = collection.find({\"stemmed\": {\"$exists\": False}})\n",
    "\n",
    "for article in tqdm(cursor, total = cursor.count()):\n",
    "    txt = article[\"text\"]\n",
    "    stemmed = stemWords(txt)\n",
    "    collection.find_and_modify({\n",
    "            \"_id\": article[\"_id\"]\n",
    "        },{\n",
    "            \"$set\": {\n",
    "                \"stemmed\": stemmed\n",
    "            }\n",
    "        })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Storing Brown corpus data in database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import brown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "collection = client.politics.brown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ids = brown.fileids(categories = [\"reviews\",\"news\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "for fileid in tqdm(ids):\n",
    "    words = brown.words(fileids=fileid)\n",
    "    stemmed = stemWords(words, t=False)\n",
    "    d = {\n",
    "        \"_id\": fileid,\n",
    "        \"stemmed\": stemmed,\n",
    "        \"category\": brown.categories(fileid)\n",
    "    }\n",
    "    collection.insert(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
